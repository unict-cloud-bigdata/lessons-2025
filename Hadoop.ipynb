{
 "cells": [
  {
   "cell_type": "raw",
   "id": "00ce5920-ec09-4527-9b66-4b27b52bb50d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Hadoop\"\n",
    "author: \"Salvo Nicotra\"\n",
    "format: \n",
    "    revealjs:\n",
    "        width: 1280\n",
    "        heigth: 800\n",
    "incremental: true  \n",
    "execute:\n",
    "  echo: true\n",
    "  warning: false\n",
    "theme: white\n",
    "chalkboard: true\n",
    "css: style.css\n",
    "smaller: true\n",
    "scrollable: true\n",
    "include-before: |\n",
    "    <img src=\"images/unict-logo.png\" class=\"custom-logo\" alt=\"Logo\">\n",
    "include-after: |\n",
    "      <div class=\"custom-footer\">\n",
    "        *** Cloud Computing and Big Data - 2024/2025 ***\n",
    "      </div>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecd160",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Hadoop ?\n",
    "[Source](https://www.cnbc.com/id/100769719)\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "Doug Cutting:\n",
    "\n",
    "> The name my kid gave a stuffed yellow elephant. Short, relatively easy to spell and pronounce, meaningless, and \n",
    "not used elsewhere: those are my naming criteria. Kids are good at generating such. Googol is a kid’s term”\n",
    "Hadoop is hardly the first unusual name to be attached to a tech company, of course. Google was born from a misspelling of \"googol\" (1 followed by 100 zeros), which itself was invented when a mathematician was playing with his nephew and together they came up with a name for really big numbers.\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://fm.cnbc.com/applications/cnbc.com/resources/img/editorial/2013/05/23/100762110-hadoop.530x298.jpg?v=1369757080)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c95df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An Operating System for Big Data\n",
    "[▶![](http://img.youtube.com/vi/ebgXN7VaIZA/0.jpg)](https://www.youtube.com/watch?v=ebgXN7VaIZA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20682b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hadoop Web Site\n",
    "\n",
    "![](https://hadoop.apache.org/hadoop-logo.jpg){.lightbox}\n",
    "\n",
    "The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.\n",
    "\n",
    "The Apache Hadoop software library is a framework that allows for the **distributed processing** of **large data sets** across clusters of computers using **simple programming models**. It is designed to **scale up** from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver **high-availability**, the library itself is designed to detect and handle failures **at the application layer**, so delivering a highly-available \n",
    "service on top of a cluster of computers, each of which may be prone to failures.\n",
    "\n",
    "<https://hadoop.apache.org/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c850598",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributed Processing \n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "It's a generic concept, derives from distribuited systems and involves:\n",
    "\n",
    "- networking\n",
    "- message exchange / protocols\n",
    "- fault tollerance\n",
    "- data distribution\n",
    "- optimization\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "Architectures:\n",
    "\n",
    "- client-server \n",
    "- 3-tier / n-tier\n",
    "- peer to peer\n",
    ":::\n",
    "::::\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665850d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### In Hadoop\n",
    "\n",
    "Distributed processing means Map Reduce\n",
    "![](https://www.glennklockwood.com/data-intensive/hadoop/mapreduce-workflow.png){.lightbox}\n",
    "\n",
    "\n",
    "<https://www.glennklockwood.com/data-intensive/hadoop/overview.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5595a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Large Data Set\n",
    "![](https://i.imgflip.com/7f12or.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cb97e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simple Programming Models\n",
    "\n",
    "#### Starting from programming language\n",
    "A programming language is made by\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "**syntax**\n",
    "\n",
    "Set of grammar rules to write correctly the source code, including:\n",
    "- symbols (variables, reserved words)\n",
    "- expressions (constructs)\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Syntax_(programming_languages))\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "**execution model**\n",
    "\n",
    "specifies the behaviour of the elements, necessary to understand what the code does including:\n",
    "- order of execution\n",
    "- interaction with runtime systems\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Execution_model)\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87bfe7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**It's like playing a song**\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Lead-sheet-wikipedia.svg/500px-Lead-sheet-wikipedia.svg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf47eab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example Python programming language\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "A Python program is read by a parser. Input to the parser is a stream of tokens, generated by the lexical analyzer. \n",
    "\n",
    "[Doc Python](https://docs.python.org/3/reference/lexical_analysis.html)\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "A Python program is constructed from code blocks. A block is a piece of Python program text that is executed as a unit. The following are blocks: a module, a function body, and a class definition. Each command typed interactively is a block.\n",
    "\n",
    "\n",
    "[Doc Python](https://docs.python.org/3/reference/executionmodel.html)\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5c5d9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### To  programming model\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "A programming model is an\n",
    "\n",
    "- execution model \n",
    "- coupled to an API or a particular pattern code.\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "So there can be two execution model\n",
    "\n",
    "- the one of the base programming language \n",
    "- the one of the programming model\n",
    "\n",
    "and they can be different!\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e1c20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "| Name     | Base programming language | execution model | \n",
    "| -------| --------------------------|----------------\n",
    "| Spark  | Java,Python,Scala         | Spark           |\n",
    "| Hadoop | Java                      | Map Reduce      |\n",
    "| Thread | C, C++, Java, Python      | POSIX Thread   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f09bb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e77f8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Why Does The High Scalability Site Exist?\n",
    "\n",
    "This site tries to bring together all the lore, art, science, practice, and experience of building scalable websites into one place so you can learn how to build your website with confidence.\n",
    "\n",
    "When it becomes clear you must grow your website or die, most people have no idea where to start. It's not a skill you learn in school or pick up from a magazine article on a plane flight home. No, building scalable systems is a body of knowledge slowly built up over time from hard won experience and many failed battles. Hopefully this site will move you further and faster along the learning curve of success.\n",
    "\n",
    "http://highscalability.com/start-here/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38fc0e",
   "metadata": {
    "cell_style": "split",
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Hadoop runs into clusters of nodes\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "Installing a Hadoop cluster typically involves unpacking the software on all the machines in the cluster or installing it via a packaging system as appropriate for your operating system. It is important to divide up the hardware into functions.\n",
    "\n",
    "Typically one machine in the cluster is designated as the NameNode and another machine as the ResourceManager, exclusively. These are the masters. Other services (such as Web App Proxy Server and MapReduce Job History server) are usually run either on dedicated hardware or on shared infrastructure, depending upon the load.\n",
    "\n",
    "The rest of the machines in the cluster act as both DataNode and NodeManager. These are the workers.\n",
    "\n",
    "[Ref](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html#Web_Interfaces)\n",
    "\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/05/exabyte_club2.png)\n",
    "\n",
    "[Ref](https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes)\n",
    ":::\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbd660",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::: {.callout-note}\n",
    "- Installing from scratch Hadoop is hard !\n",
    "- That's why hadoop vendors first and cloud provider later did start package Hadoop \n",
    "- Now it's time for Hadoop in Kubernetes!\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56ca7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### High Avalability at application layer\n",
    "\n",
    "> High availability (HA) is a characteristic of a system which aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period.\n",
    "\n",
    "**Principles**\n",
    "There are three principles of systems design in reliability engineering which can help achieve high availability.\n",
    "\n",
    "1. Elimination of single points of failure. This means adding or building redundancy into the system so that failure of a component does not mean failure of the entire system.\n",
    "2. Reliable crossover. In redundant systems, the crossover point itself tends to become a single point of failure. Reliable systems must provide for reliable crossover.\n",
    "3. Detection of failures as they occur. If the two principles above are observed, then a user may never see a failure – but the maintenance activity must.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d19e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### In hadoop\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "**At Storage level: Data Replication**\n",
    "\n",
    "HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks; all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance. The block size and replication factor are configurable per file. An application can specify the number of replicas of a file. The replication factor can be specified at file creation time and can be changed later. Files in HDFS are write-once and have strictly one writer at any time.\n",
    "\n",
    "The NameNode makes all decisions regarding replication of blocks. It periodically receives a Heartbeat and a Blockreport from each of the DataNodes in the cluster. Receipt of a Heartbeat implies that the DataNode is functioning properly. A Blockreport contains a list of all blocks on a DataNode.\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "**At computing level: Application Master** \n",
    "\n",
    "When the application master is notified of a task attempt that has failed, it will reschedule execution of the task. The application master will try to avoid rescheduling the task on a node manager where it has previously failed. Furthermore, if a task fails four times, it will not be retried again. \n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a8f1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Hadoop Components "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af79a93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e737c5",
   "metadata": {
    "cell_style": "split",
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Hadoop Common**\n",
    "\n",
    "The common utilities that support the other Hadoop modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c727f27",
   "metadata": {
    "cell_style": "split",
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Hadoop YARN**\n",
    "\n",
    "A framework for job scheduling and cluster resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612b420",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop Distributed File System (HDFS™)**\n",
    "\n",
    "A distributed file system that provides high-throughput access to application data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d1eaa",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop MapReduce** \n",
    "\n",
    "A YARN-based system for parallel processing of large data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908339d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Related Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79237480",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ambari™: A web-based tool for provisioning, managing, and monitoring Apache Hadoop clusters which includes support for Hadoop HDFS, Hadoop MapReduce, Hive, HCatalog, HBase, ZooKeeper, Oozie, Pig and Sqoop. Ambari also provides a dashboard for viewing cluster health such as heatmaps and ability to view MapReduce, Pig and Hive applications visually alongwith features to diagnose their performance characteristics in a user-friendly manner.\n",
    "- Avro™: A data serialization system.\n",
    "- Cassandra™: A scalable multi-master database with no single points of failure.\n",
    "- Chukwa™: A data collection system for managing large distributed systems.\n",
    "- HBase™: A scalable, distributed database that supports structured data storage for large tables.\n",
    "- Hive™: A data warehouse infrastructure that provides data summarization and ad hoc querying.\n",
    "- Mahout™: A Scalable machine learning and data mining library.\n",
    "- Ozone™: A scalable, redundant, and distributed object store for Hadoop.\n",
    "- Pig™: A high-level data-flow language and execution framework for parallel computation.\n",
    "- Spark™: A fast and general compute engine for Hadoop data. Spark provides a simple and expressive programming model that supports a wide range of applications, including ETL, machine learning, stream processing, and graph computation.\n",
    "- Submarine: A unified AI platform which allows engineers and data scientists to run Machine Learning and Deep Learning workload in distributed cluster.\n",
    "- Tez™: A generalized data-flow programming framework, built on Hadoop YARN, which provides a powerful and flexible engine to execute an arbitrary DAG of tasks to process data for both batch and interactive use-cases. Tez is being adopted by Hive™, Pig™ and other frameworks in the Hadoop ecosystem, and also by other commercial software (e.g. ETL tools), to replace Hadoop™ MapReduce as the underlying execution engine.\n",
    "- ZooKeeper™: A high-performance coordination service for distributed applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67ccf25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hadoop ecosystem table (retired)\n",
    "https://hadoopecosystemtable.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6be89f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The Good and the Bad of Hadoop Big Data Framework\n",
    "<https://www.altexsoft.com/blog/hadoop-pros-cons/>\n",
    "::: {.callout-note}\n",
    "What does it take to store all New York Times articles published between 1855 and 1922? Depending on how you measure it, the answer is 11 million newspaper pages or just one Hadoop cluster and one tech specialist who can move 4 terabytes of textual data to a new location in 24 hours.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e133d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "###  Hadoop organizations benefits\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "Hadoop can be useful for a wide range of organizations and industries that work with large amounts of data. Here are a few examples of who might benefit from using Hadoop:\n",
    "\n",
    "- E-commerce companies that need to process large volumes of customer data to gain insights into purchasing patterns, product recommendations, and customer behavior.\n",
    "- Healthcare organizations that need to analyze patient data for medical research, disease diagnosis, and treatment.\n",
    "- Financial institutions that need to analyze large amounts of transaction data to detect fraud and identify trends in financial markets.\n",
    "- Government agencies that need to process large amounts of data for public safety, security, and policy-making purposes.\n",
    "- Social media companies that need to process large amounts of user-generated data for personalized recommendations, targeted advertising, and trend analysis.\n",
    "\n",
    "In general, any organization that needs to process and analyze large volumes of data can benefit from using Hadoop.\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "According to a study by the Business Application Research Center (BARC), Hadoop found intensive use as\n",
    "\n",
    "- a runtime environment (sandbox) for classic business intelligence (BI), advanced analysis of large volumes of data, predictive maintenance, and data discovery and exploration;\n",
    "- a store for raw data;\n",
    "- a tool for large-scale data integration; and\n",
    " a suitable technology to implement data lake architecture.\n",
    ":::\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c9653",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Industries\n",
    "\n",
    "Many industries, from manufacturing to banking to transportation, take advantage of what Hadoop can offer. And the number of companies adopting the platform is projected to increase by 2030. According to the latest report by Allied Market Research, the Big Data platform will see the biggest rise in adoption in telecommunication, healthcare, and government sectors.\n",
    "\n",
    "![](https://www.altexsoft.com/static/blog-post/2023/11/5b0f66f8-9afa-43d1-9938-635fabcad4f3.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e96fbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Why Hadoop has been so important ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bf962",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## To be able to compute big data\n",
    "\n",
    "> According to an article published by IBM, traditional computing systems are designed to handle data sets that can fit into a single machine's memory. As the size of the data set grows beyond the capacity of a single machine, traditional systems become inefficient, slow, and expensive. In contrast, Hadoop is designed to handle data sets that are too large to fit into a single machine's memory by distributing the data and processing across a cluster of machines. This approach allows for parallel processing of large data sets, making Hadoop faster and more efficient than traditional systems for large-scale data processing. Additionally, Hadoop's fault-tolerant architecture enables it to recover from hardware failures, which is essential for large data sets that may span multiple machines.\n",
    "\n",
    "IBM. \"What is Hadoop?\". IBM.com. https://www.ibm.com/cloud/learn/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0efaec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Is still valid ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3ce4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Hadoop is still a valid technology in 2024. While there are other big data technologies that have emerged in recent years, such as Apache Spark and Apache Flink, Hadoop remains a popular and widely used platform for distributed computing and big data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05e72e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Hadoop has a large and active community of users and developers who continue to improve and maintain the platform. In addition, many companies have invested heavily in Hadoop infrastructure and continue to use it as a core component of their big data processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3280d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, it's worth noting that Hadoop has also evolved over time to incorporate newer technologies and approaches, such as the integration of Spark as a processing engine and the use of cloud-based Hadoop offerings. As such, it's important to stay up-to-date with the latest developments in the Hadoop ecosystem to ensure that you are making the most of this powerful technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb25cbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df68cad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.maximizemarketresearch.com/wp-content/uploads/2019/11/Global-Hadoop-Big-Data-Analytics-Market-1.png)\n",
    "https://www.maximizemarketresearch.com/market-report/global-hadoop-big-data-analytics-market/6866/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd39bc6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.acumenresearchandconsulting.com/reportimages//Infographics_Global-Hadoop-Market-1.jpg)\n",
    "https://www.acumenresearchandconsulting.com/hadoop-market"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad443c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Hype Cycle for Data Management \n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/Figure_1_Hype_Cycle_for_Data_Management_2023.png){.lightbox}\n",
    "\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/Hype_Cycle_for_Data_Management_2024.png){.lightbox}\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711b7c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# How it works ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d17f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Map Reduce\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*icizuNuhN_1VFIT1_voWsw.jpeg){.lightbox}\n",
    "\n",
    "\n",
    "<https://towardsdatascience.com/series-on-distributed-computing-1-mapreduce-fcc3cc2dfb5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71737c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## HDFS\n",
    "![](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png){.lightbox}\n",
    "\n",
    "https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baabeab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Where to use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78978924",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![](https://i.imgflip.com/7f1pf6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb94cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### AWS EMR\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "Easily run and scale Apache Spark, Hive, Presto, and other big data workloads\n",
    "\n",
    "https://aws.amazon.com/emr/\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://d1.awsstatic.com/products/EMR/Product-Page-Diagram_Amazon-EMR.803d6adad956ba21ceb96311d15e5022c2b6722b.png)\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04ef47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Azure HD Insight\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "Run popular open-source frameworks—including Apache Hadoop, Spark, Hive, Kafka, and more—using Azure HDInsight, a customizable, enterprise-grade service for open-source analytics. Effortlessly process massive amounts of data and get all the benefits of the broad open-source project ecosystem with the global scale of Azure. Easily migrate your big data workloads and processing to the cloud.\n",
    "\n",
    "https://azure.microsoft.com/en-gb/products/hdinsight/\n",
    "\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/hdinsight_integrate?resMode=sharp2&op_usm=1.5,0.65,15,0&wid=2908&hei=1724&qlt=100&fmt=png-alpha&fit=constrain)\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f17b86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Google Cloud - Dataproc\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "Dataproc is a fully managed and highly scalable service for running Apache Hadoop, Apache Spark, Apache Flink, Presto, and 30+ open source tools and frameworks. Use Dataproc for data lake modernization, ETL, and secure data science, at scale, integrated with Google Cloud, at a fraction of the cost.\n",
    "\n",
    "https://cloud.google.com/dataproc\n",
    "\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://4.bp.blogspot.com/-iIEZ8nIeFTk/Vh16SPiU9KI/AAAAAAAABdI/Fr9zYhYqQkI/s640/Dataproc.png)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed9785",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Time to do practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb97d07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## A Word Count with Map Reduce on DataProc\n",
    "\n",
    "- Dasbhoard: <https://miro.com/app/board/uXjVMcdLcug=/?share_link_id=121090137939>\n",
    "- Source Example: <https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordCount.java>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea02068",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Spoiler of next lessons\n",
    "https://6sense.com/tech/big-data-analytics/databricks-vs-apachehadoop\n",
    "\n",
    "![](images/hadoopvsspark6sense.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36902e92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Tutorials\n",
    "- https://www.cloudskillsboost.google/focuses/672?catalog_rank=%7B%22rank%22%3A9%2C%22num_filters%22%3A0%2C%22has_search%22%3Atrue%7D&parent=catalog&search_id=22899007\n",
    "- https://cloud.google.com/composer/docs/tutorials/hadoop-wordcount-job\n",
    "- https://www.geeksforgeeks.org/introduction-to-apache-pig/\n",
    "- https://towardsdatascience.com/the-charm-of-apache-pig-fdc92b5cc3b4\n",
    "- https://codelabs.developers.google.com/codelabs/intro-cloud-composer#0\n",
    "- https://www.freecodecamp.org/news/what-is-google-dataproc/\n",
    "- https://github.com/apache/hadoop/tree/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples\n",
    "- https://medium.com/edureka/mapreduce-tutorial-3d9535ddbe7c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42316ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0398da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- https://hadoop.apache.org/\n",
    "- https://www.linkedin.com/learning/learning-hadoop-2/getting-started-with-hadoop?autoplay=true\n",
    "- https://www.projectpro.io/article/hadoop-vs-spark-not-mutually-exclusive-but-better-together/235\n",
    "- https://towardsdatascience.com/series-on-distributed-computing-1-mapreduce-fcc3cc2dfb5\n",
    "- https://www.databricks.com/glossary/hadoop-ecosystem\n",
    "- https://medium.com/geekculture/mapreduce-with-python-5d12a772d5b3\n",
    "- https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes\n",
    "- https://www.uber.com/en-IT/blog/scaling-hdfs/\n",
    "- https://engineering.linkedin.com/blog/2021/the-exabyte-club--linkedin-s-journey-of-scaling-the-hadoop-distr\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": "true",
   "footer": "<div class=\"tswd-footer\"> *** Cloud Computing and Big Data - 2024 ***</div>",
   "header": "<div class=\"tswd-header\"></div>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
